{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1-mnist-with-keras.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[{"file_id":"https://github.com/tensorflow/workshops/blob/master/notebooks/1-mnist-with-keras.ipynb","timestamp":1527554019454}],"collapsed_sections":[]}},"cells":[{"metadata":{"id":"IZrAitlFLdEZ","colab_type":"text"},"cell_type":"markdown","source":["# MNIST with tf.keras\n","\n","Welcome! In this lab, you'll learn how to train an image classifier train on the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) - the \"hello world\" of computer vision. You'll go through all the steps, including loading the data, building and training a model, calculating the accuracy, and making predictions. Our focus here is on the code. For more on any of the concepts below, see [https://ai.google/education](https://ai.google/education)."]},{"metadata":{"id":"jSmUsjJfMEqC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!pip install -q -U tensorflow==1.8.0\n","import tensorflow as tf\n","\n","import numpy as np"],"execution_count":0,"outputs":[]},{"metadata":{"id":"B8Lhscw0NDln","colab_type":"text"},"cell_type":"markdown","source":["### Step 1: Download the dataset\n","\n","The MNIST dataset contains thousands of grayscale images of handwritten digits."]},{"metadata":{"id":"FKiwTuT-NE6f","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":69},"outputId":"2509fa1e-ac67-46f5-e443-171d3f5be9e2","executionInfo":{"status":"ok","timestamp":1529508119066,"user_tz":240,"elapsed":3769,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 3s 0us/step\n","11501568/11490434 [==============================] - 3s 0us/step\n"],"name":"stdout"}]},{"metadata":{"id":"eEFU58MaNPpk","colab_type":"text"},"cell_type":"markdown","source":["### Step 2) Visualize the data\n","Let's see how the images look. This function shows a random example along with it's corresponding label."]},{"metadata":{"id":"AwxNOsCMNNGd","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":382},"outputId":"f82e06a9-316d-49ea-cf50-03118958d70b","executionInfo":{"status":"ok","timestamp":1529508143458,"user_tz":240,"elapsed":423,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["import random\n","import matplotlib.pyplot as plt\n","\n","i = random.randint(0, 100)\n","\n","print(\"Label: %s\" % train_labels[i])\n","plt.imshow(train_images[i])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Label: 5\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f5f7bcfe450>"]},"metadata":{"tags":[]},"execution_count":3},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nADD4H+IjnWidBYHfAAAAAElFTkSuQmCC\n","text/plain":["<matplotlib.figure.Figure at 0x7f5f7c1a3750>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"e2n2NVdKNk5i","colab_type":"text"},"cell_type":"markdown","source":["### Step 3) Understand the data format\n","\n","We are given the images as a 3-D array of integer values that is of shape (*N*, 28, 28), where *N* is the number of images in the training or test set. The labels are 1-D array of the integer values of each image."]},{"metadata":{"id":"TTj2ZWMBN24i","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":52},"outputId":"4515e64f-e52e-44fe-a55e-c61ec599593e","executionInfo":{"status":"ok","timestamp":1529508153350,"user_tz":240,"elapsed":276,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["print(train_images.shape)\n","print(train_labels.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(60000, 28, 28)\n","(60000,)\n"],"name":"stdout"}]},{"metadata":{"id":"Eo_cZXaqODnZ","colab_type":"text"},"cell_type":"markdown","source":["### Step 4) Reformat the images\n","Here, we'll flatten (or unstack) the images. There are deep learning techniques that work with 2d images directly (rather than their flattened representation), but we'll start with this format. Instead of working with a 28 by 28 *image*, we'll unstack it into a 28 \\* 28 = 784 length *array*.\n","\n","* We want to convert the 3-D array of shape (*N*, 28, 28) to a 2-D array of shape (*N*, 784) where the second dimension is just an array of all the pixels in an image. This is called flattening, or unstacking, the images. \n","* We also want to convert the pixel values from a number between 0 and 255 to a number between 0 and 1."]},{"metadata":{"id":"OgnV5FJjP5Vz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":3421},"outputId":"9be1a6a7-d9d6-4840-a061-764aabd17837","executionInfo":{"status":"ok","timestamp":1529508685705,"user_tz":240,"elapsed":730,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["TRAINING_SIZE = len(train_images)\n","TEST_SIZE = len(test_images)\n","\n","# Reshape from (N, 28, 28) to (N, 784)\n","train_images = np.reshape(train_images, (TRAINING_SIZE, 784))\n","test_images = np.reshape(test_images, (TEST_SIZE, 784))\n","\n","# Convert the array to float32 as opposed to uint8\n","train_images = train_images.astype(np.float32)\n","test_images = test_images.astype(np.float32)\n","\n","# Convert the pixel values from integers between 0 and 255 to floats between 0 and 1\n","train_images /= 255\n","test_images /=  255\n","\n","train_images[0]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       4.6136101e-05, 2.7681663e-04, 2.7681663e-04, 2.7681663e-04,\n","       1.9377163e-03, 2.0915035e-03, 2.6912726e-03, 3.9984621e-04,\n","       2.5528644e-03, 3.9215689e-03, 3.7985391e-03, 1.9530950e-03,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       4.6136102e-04, 5.5363326e-04, 1.4455979e-03, 2.3683200e-03,\n","       2.6143792e-03, 3.8908112e-03, 3.8908112e-03, 3.8908112e-03,\n","       3.8908112e-03, 3.8908112e-03, 3.4602077e-03, 2.6451366e-03,\n","       3.8908112e-03, 3.7216456e-03, 2.9988466e-03, 9.8423695e-04,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.5355632e-04,\n","       3.6601308e-03, 3.8908112e-03, 3.8908112e-03, 3.8908112e-03,\n","       3.8908112e-03, 3.8908112e-03, 3.8908112e-03, 3.8908112e-03,\n","       3.8908112e-03, 3.8600538e-03, 1.4302192e-03, 1.2610535e-03,\n","       1.2610535e-03, 8.6120726e-04, 5.9976935e-04, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.7681663e-04,\n","       3.3679355e-03, 3.8908112e-03, 3.8908112e-03, 3.8908112e-03,\n","       3.8908112e-03, 3.8908112e-03, 3.0449827e-03, 2.7989235e-03,\n","       3.7985391e-03, 3.7062669e-03, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       1.2302961e-03, 2.3990774e-03, 1.6455210e-03, 3.8908112e-03,\n","       3.8908112e-03, 3.1526336e-03, 1.6916571e-04, 0.0000000e+00,\n","       6.6128414e-04, 2.3683200e-03, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 2.1530181e-04, 1.5378702e-05, 2.3683200e-03,\n","       3.8908112e-03, 1.3840831e-03, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.1376396e-03,\n","       3.8908112e-03, 2.9219531e-03, 3.0757405e-05, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.6916571e-04,\n","       2.9219531e-03, 3.8908112e-03, 1.0765091e-03, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       5.3825456e-04, 3.7062669e-03, 3.4602077e-03, 2.4605922e-03,\n","       1.6608997e-03, 1.5378702e-05, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 1.2456748e-03, 3.6908882e-03, 3.8908112e-03,\n","       3.8908112e-03, 1.8300654e-03, 3.8446751e-04, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 6.9204153e-04, 2.8604383e-03,\n","       3.8908112e-03, 3.8908112e-03, 2.3068052e-03, 4.1522493e-04,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.4605924e-04,\n","       1.4302192e-03, 3.8754325e-03, 3.8908112e-03, 2.8758170e-03,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 3.8292964e-03, 3.8908112e-03, 3.8292964e-03,\n","       9.8423695e-04, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 7.0742023e-04, 1.9992313e-03,\n","       2.8143022e-03, 3.8908112e-03, 3.8908112e-03, 3.1833909e-03,\n","       3.0757405e-05, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       5.9976935e-04, 2.2760478e-03, 3.5217225e-03, 3.8908112e-03,\n","       3.8908112e-03, 3.8908112e-03, 3.8446751e-03, 2.7989235e-03,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 3.6908881e-04, 1.7531719e-03,\n","       3.3986929e-03, 3.8908112e-03, 3.8908112e-03, 3.8908112e-03,\n","       3.8908112e-03, 3.0911188e-03, 1.1995387e-03, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       3.5371011e-04, 1.0149943e-03, 3.2756634e-03, 3.8908112e-03,\n","       3.8908112e-03, 3.8908112e-03, 3.8908112e-03, 3.0449827e-03,\n","       1.2456748e-03, 3.0757405e-05, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 2.7681663e-04, 2.6297579e-03,\n","       3.3679355e-03, 3.8908112e-03, 3.8908112e-03, 3.8908112e-03,\n","       3.8908112e-03, 2.9988466e-03, 1.2302961e-03, 1.3840832e-04,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       8.4582856e-04, 2.6451366e-03, 3.4755864e-03, 3.8908112e-03,\n","       3.8908112e-03, 3.8908112e-03, 3.8908112e-03, 3.7524030e-03,\n","       2.0453674e-03, 1.6916571e-04, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       2.0915035e-03, 3.8908112e-03, 3.8908112e-03, 3.8908112e-03,\n","       3.2602844e-03, 2.0761248e-03, 2.0299887e-03, 2.4605924e-04,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n","      dtype=float32)"]},"metadata":{"tags":[]},"execution_count":6}]},{"metadata":{"id":"GI25z0StQH-P","colab_type":"text"},"cell_type":"markdown","source":["### Step 5) Reformat the labels\n","\n","Next, we want to convert the labels from an integer format (e.g., \"2\"), to a [one hot encoding](https://en.wikipedia.org/wiki/One-hot) (e.g., \"0, 0, 1, 0, 0, 0, 0, 0, 0, 0\"). To do so, we'll use the `tf.keras.utils.to_categorical` [function](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) function."]},{"metadata":{"id":"E9yrkEENQ9Vz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":50},"outputId":"615b33ae-a7bc-41ae-8d18-71244308ff35","executionInfo":{"status":"ok","timestamp":1527554221088,"user_tz":240,"elapsed":410,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["NUM_DIGITS = 10\n","\n","print(\"Before\", train_labels[0]) # The format of the labels before conversion\n","\n","train_labels  = tf.keras.utils.to_categorical(train_labels, NUM_DIGITS)\n","\n","print(\"After\", train_labels[0]) # The format of the labels after conversion\n","\n","test_labels = tf.keras.utils.to_categorical(test_labels, NUM_DIGITS)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["('Before', 5)\n","('After', array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]))\n"],"name":"stdout"}]},{"metadata":{"id":"pjdbemHURkpv","colab_type":"text"},"cell_type":"markdown","source":["### Step 6) Build the model\n","\n","Now, we'll create our neural network using the [Keras Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential). \n","* Architecture wise, we'll single layer network. \n","* The hidden layer will have 512 units using the [ReLU](https://www.tensorflow.org/api_docs/python/tf/keras/activations/relu) activation function. \n","* The output layer will have 10 units and use [softmax](https://www.tensorflow.org/api_docs/python/tf/keras/activations/softmax) function. \n","* Notice, we specify the input shape on the first layer. If you add subsequent layers, this is not necessary. \n","* We will use the [categorical crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_crossentropy) loss function, and the [RMSProp](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop) optimizer."]},{"metadata":{"id":"mNscbvHkUrMc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":202},"outputId":"01f452be-c48d-41e0-e693-30fc80d6b71d","executionInfo":{"status":"ok","timestamp":1527554270475,"user_tz":240,"elapsed":417,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["model = tf.keras.Sequential()\n","model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(784,)))\n","model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n","\n","# We will now compile and print out a summary of our model\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])\n","\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 512)               401920    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                5130      \n","=================================================================\n","Total params: 407,050\n","Trainable params: 407,050\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"k3br9Yi6VuBT","colab_type":"text"},"cell_type":"markdown","source":["### Step 7) Training\n","\n","Next, we will train the model by using the [fit method](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#fit) for 5 [epochs](https://www.quora.com/What-is-epochs-in-machine-learning). We will keep track of the training loss and accuracy as we go. Please be patient as this step may take a while depending on your hardware."]},{"metadata":{"id":"gBs0LwqcVXx6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":202},"outputId":"f6f72807-a506-4d77-a866-1b2609d0dc2d","executionInfo":{"status":"ok","timestamp":1527554335587,"user_tz":240,"elapsed":49727,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["model.fit(train_images, train_labels, epochs=5)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","60000/60000 [==============================] - 9s 158us/step - loss: 0.2019 - acc: 0.9408\n","Epoch 2/5\n","60000/60000 [==============================] - 10s 165us/step - loss: 0.0877 - acc: 0.9740\n","Epoch 3/5\n","48800/60000 [=======================>......] - ETA: 1s - loss: 0.0622 - acc: 0.9825"],"name":"stdout"},{"output_type":"stream","text":["60000/60000 [==============================] - 10s 166us/step - loss: 0.0632 - acc: 0.9825\n","Epoch 4/5\n","60000/60000 [==============================] - 10s 166us/step - loss: 0.0493 - acc: 0.9860\n","Epoch 5/5\n","60000/60000 [==============================] - 10s 165us/step - loss: 0.0409 - acc: 0.9888\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras._impl.keras.callbacks.History at 0x7fa67e09aa10>"]},"metadata":{"tags":[]},"execution_count":8}]},{"metadata":{"id":"rcYMPkwkWIPq","colab_type":"text"},"cell_type":"markdown","source":["### Step 8) Testing\n","Now that we have trained our model, we want to evaluate it. Sure, our model is >97% accurate on the training set, but what about on data it hasn't seen before? The test accuracy is a good metric for that."]},{"metadata":{"id":"iuqDe4NiWBpU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":50},"outputId":"9da88b5b-693d-46b2-a08e-4dbf103652bb","executionInfo":{"status":"ok","timestamp":1527554353651,"user_tz":240,"elapsed":759,"user":{"displayName":"Caroline J","photoUrl":"//lh5.googleusercontent.com/-UW6T_Czu5Tc/AAAAAAAAAAI/AAAAAAAAAmk/_PdmajiiHBY/s50-c-k-no/photo.jpg","userId":"115113466279912359883"}}},"cell_type":"code","source":["loss, accuracy = model.evaluate(test_images, test_labels)\n","print('Test accuracy: %.2f' % (accuracy))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["10000/10000 [==============================] - 0s 41us/step\n","Test accuracy: 0.98\n"],"name":"stdout"}]},{"metadata":{"id":"jo-yoMwvXkw6","colab_type":"text"},"cell_type":"markdown","source":["## Congratulations\n","You have successfully used TensorFlow Keras to train a model on the MNIST dataset."]},{"metadata":{"id":"pEuRxYVGVce0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"cellView":"form"},"cell_type":"code","source":["#@title Wow that was easy!\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7vZEIwyNVxIZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}